{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "ChatCompletion(id='cdbf8f42-79b4-47cc-a3af-3272f8e68a0d', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I'd be happy to help answer your question, but it's important to note that the exact number of stars in the universe is currently unknown. Estimates suggest that there are between 1 trillion and 2 trillion galaxies in the observable universe, and each of these galaxies may contain between 100 billion and 400 billion stars. So, the total number of stars could be anywhere from 10 sextillion to 400 sextillion (that's a 1 followed by 21 or 23 zeros). However, it's important to remember that we're still discovering new galaxies and stars, so this is just an estimate based on what we know so far. If you have any other questions, feel free to ask!\", role='assistant', function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})], created=5090801, model='mistral-7b-instruct', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=166, prompt_tokens=41, total_tokens=207))\n",
      "('id', 'f1687405-b4eb-411b-88fd-dc23af11b3d5')\n",
      "('choices', [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I'd be happy to help answer your question, but it's important to note that the number of stars in the universe is currently an estimate and not an exact number. According to current scientific understanding, there are around 1 trillion â€“ 2 trillion galaxies in the observable universe, and each of these galaxies contains between 100 billion and 400 billion stars. So, the total number of stars in the universe could be anywhere from 10 sextillion to 200 sextillion (that's a 1 followed by 23 zeros). However, it's important to keep in mind that this is just an estimate based on our current observations and understanding of the universe, and there may be many more stars that are too far away or too small for us to detect. I hope this information is helpful! Let me know if you have any other questions.\", role='assistant', function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})])\n",
      "('created', 9835318)\n",
      "('model', 'mistral-7b-instruct')\n",
      "('object', 'chat.completion')\n",
      "('system_fingerprint', None)\n",
      "('usage', CompletionUsage(completion_tokens=188, prompt_tokens=41, total_tokens=229))\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the value of the environment key\n",
    "YOUR_API_KEY = os.getenv(\"PPX_API_KEY\")\n",
    "print(YOUR_API_KEY)\n",
    "\n",
    "def run_1():\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are an expert programmer that converts code from Fortran to Rust.\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"How many stars are in the universe?\"\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    client = OpenAI(api_key=YOUR_API_KEY, base_url=\"https://api.perplexity.ai\")\n",
    "\n",
    "    # chat completion without streaming\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"mistral-7b-instruct\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    print(response)\n",
    "\n",
    "    # # chat completion with streaming\n",
    "    # response_stream = client.chat.completions.create(\n",
    "    #     model=\"codellama-70b-instruct\",\n",
    "    #     messages=messages,\n",
    "    # )\n",
    "    # for response in response_stream:\n",
    "    #     print(response)\n",
    "    # return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = \"Examine the provided Fortran code snippet and it's detailed explanation carefully. Now, translate the Fortran code into idiomatic Rust, focusing on leveraging Rust's unique features such as memory safety and error handling. Ensure the Rust code is idiomatic, adheres to the language's best practices, and maintains the structural and functional integrity of the original Fortran code. In your translation, address language-specific nuances, syntax variations, and adherence to idiomatic conventions for Rust. \\\n",
    "\\\n",
    "The aim is to produce a Rust code version that integrates smoothly into Rust environments.\"\n",
    "\n",
    "def run_2():\n",
    "        messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are an expert programmer that converts code from Fortran to Rust.\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"How many stars are in the universe?\"\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    client = OpenAI(api_key=YOUR_API_KEY, base_url=\"https://api.perplexity.ai\")\n",
    "\n",
    "    # chat completion without streaming\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"mistral-7b-instruct\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    print(response)\n",
    "\n",
    "    # chat completion with streaming\n",
    "    response_stream = client.chat.completions.create(\n",
    "        model=\"mistral-7b-instruct\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    for response in response_stream:\n",
    "        print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "host",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
